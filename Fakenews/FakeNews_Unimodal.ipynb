{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fa8a81eb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 587,
     "status": "ok",
     "timestamp": 1687184054209,
     "user": {
      "displayName": "Tahuruzzoha Tuhin",
      "userId": "08192377551345148302"
     },
     "user_tz": -360
    },
    "id": "fa8a81eb",
    "outputId": "4f6b0f95-cb8c-489a-bd64-a148e8a09aa3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activating auto-logging. Current session state plus future input saved.\n",
      "Filename       : my_notebook.log\n",
      "Mode           : backup\n",
      "Output logging : True\n",
      "Raw input log  : False\n",
      "Timestamping   : True\n",
      "State          : active\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "%logstart -o -t my_notebook.log\n",
    "\n",
    "# Requirements and libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "from collections import defaultdict\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Embedding, Conv1D, GlobalMaxPooling1D, Dense, Activation, Flatten\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Concatenate\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de7186d8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1635,
     "status": "ok",
     "timestamp": 1687183191760,
     "user": {
      "displayName": "Tahuruzzoha Tuhin",
      "userId": "08192377551345148302"
     },
     "user_tz": -360
    },
    "id": "de7186d8",
    "outputId": "664f5682-4762-4769-d2ba-eeb4c9d1acd8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /root/nltk_data...\n",
      "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
      "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download Requirements and libraries\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "yX4Z4nUTxMn1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 34310,
     "status": "ok",
     "timestamp": 1687183298264,
     "user": {
      "displayName": "Tahuruzzoha Tuhin",
      "userId": "08192377551345148302"
     },
     "user_tz": -360
    },
    "id": "yX4Z4nUTxMn1",
    "outputId": "be3bcabe-a529-4edd-c207-7b65b0346da8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3a115e6",
   "metadata": {
    "id": "e3a115e6"
   },
   "outputs": [],
   "source": [
    "\n",
    "# # Read data source and show the head\n",
    "# df1 = pd.read_table('./all_comments.tsv/all_comments.tsv',)\n",
    "# df1.dataframeName = 'Fake News'\n",
    "# nRow, nCol = df1.shape\n",
    "# print(f'There are {nRow} rows and {nCol} columns')\n",
    "# df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1582c1d7",
   "metadata": {
    "id": "1582c1d7"
   },
   "outputs": [],
   "source": [
    "\n",
    "# # Drop unused column of data and slice\n",
    "# df2=df1.drop(['Unnamed: 0','author','parent_id','submission_id', 'ups'],axis=1)\n",
    "# df3 = df2[:100]\n",
    "# print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fea3c723",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "executionInfo": {
     "elapsed": 1527,
     "status": "ok",
     "timestamp": 1687183334893,
     "user": {
      "displayName": "Tahuruzzoha Tuhin",
      "userId": "08192377551345148302"
     },
     "user_tz": -360
    },
    "id": "fea3c723",
    "outputId": "75cb659e-1ccf-401c-b618-fa106c4df2af"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-6eb3db40-df58-4184-a56d-f9f44f19d0ee\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>body</th>\n",
       "      <th>isTopLevel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>f4deplg</td>\n",
       "      <td>Scroll, scroll, scroll.  Pause.  Scroll back u...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>f4d79bi</td>\n",
       "      <td>A lot of the people who felt quite strongly ab...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>f4ddmlk</td>\n",
       "      <td>T H E   S P H E R E   S H A L L   R I S E   A ...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>f4dknfn</td>\n",
       "      <td>All hail the cube of justice</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>f4dgdur</td>\n",
       "      <td>That is glorious.</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6eb3db40-df58-4184-a56d-f9f44f19d0ee')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-6eb3db40-df58-4184-a56d-f9f44f19d0ee button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-6eb3db40-df58-4184-a56d-f9f44f19d0ee');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "   Unnamed: 0       id                                               body  \\\n",
       "0           0  f4deplg  Scroll, scroll, scroll.  Pause.  Scroll back u...   \n",
       "1           1  f4d79bi  A lot of the people who felt quite strongly ab...   \n",
       "2           2  f4ddmlk  T H E   S P H E R E   S H A L L   R I S E   A ...   \n",
       "3           3  f4dknfn                       All hail the cube of justice   \n",
       "4           4  f4dgdur                                  That is glorious.   \n",
       "\n",
       "   isTopLevel  \n",
       "0        True  \n",
       "1        True  \n",
       "2        True  \n",
       "3        True  \n",
       "4        True  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a DataFrame with the predicted labels\n",
    "# predicted_df = pd.DataFrame({'predicted_label': predicted_labels})\n",
    "# Export the DataFrame to Excel\n",
    "# df3.to_csv('slice_100.csv')\n",
    "df3 = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/slice_100.csv')\n",
    "df3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "79ed4c21",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 621,
     "status": "ok",
     "timestamp": 1687183411628,
     "user": {
      "displayName": "Tahuruzzoha Tuhin",
      "userId": "08192377551345148302"
     },
     "user_tz": -360
    },
    "id": "79ed4c21",
    "outputId": "470f57f0-088a-4345-9042-ca9dc56a02b6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Extract necessary column of data and convert into list\n",
    "id = df3['id'].tolist()\n",
    "body = df3['body'].tolist()\n",
    "isTopLevel = df3['isTopLevel'].tolist()\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "54da0198",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 642,
     "status": "ok",
     "timestamp": 1687183414607,
     "user": {
      "displayName": "Tahuruzzoha Tuhin",
      "userId": "08192377551345148302"
     },
     "user_tz": -360
    },
    "id": "54da0198",
    "outputId": "eaf6af2c-b341-4b79-9296-7e009bd37605",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Define the preprocessing functions\n",
    "def preprocess_text(text):\n",
    "    # Remove stopwords, punctuations, numbers, and multiple spaces\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = word_tokenize(text)\n",
    "    filtered_tokens = [token.lower() for token in tokens if token.isalpha() and token.lower() not in stop_words]\n",
    "    return filtered_tokens\n",
    "\n",
    "def lemmatize_text(tokens):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemmatized_tokens = [lemmatizer.lemmatize(token, get_wordnet_pos(token)) for token in tokens]\n",
    "    return lemmatized_tokens\n",
    "\n",
    "def get_wordnet_pos(token):\n",
    "    # Map POS tag to first character lemmatize() accepts\n",
    "    tag = nltk.pos_tag([token])[0][1][0].upper()\n",
    "    tag_dict = {'J': wordnet.ADJ, 'N': wordnet.NOUN, 'V': wordnet.VERB, 'R': wordnet.ADV}\n",
    "    return tag_dict.get(tag, wordnet.NOUN)\n",
    "\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1f556dd7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2260,
     "status": "ok",
     "timestamp": 1687183421116,
     "user": {
      "displayName": "Tahuruzzoha Tuhin",
      "userId": "08192377551345148302"
     },
     "user_tz": -360
    },
    "id": "1f556dd7",
    "outputId": "81e8dd0d-662e-4fc0-dd35-2fbcce3ae204"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "# Sample Fakeddit dataset\n",
    "data = {\n",
    "    'id': id,\n",
    "    'body': body,\n",
    "    'isTopLevel': isTopLevel\n",
    "}\n",
    "\n",
    "#Convert the dictionary to pandas Dataframe\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Preprocess the 'body' column\n",
    "df['body'] = df['body'].fillna(\"\")\n",
    "df['body'] = df['body'].apply(preprocess_text)\n",
    "df['body'] = df['body'].apply(lemmatize_text)\n",
    "\n",
    "# Building the vocabulary and mapping words to integer numbers\n",
    "word_to_int = defaultdict(lambda: len(word_to_int) + 1)  # Assign unique integer to each word\n",
    "\n",
    "# Transforming each text into a sequence of integers\n",
    "df['body'] = df['body'].apply(lambda tokens: [word_to_int[token] for token in tokens])\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9ac67da0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 627,
     "status": "ok",
     "timestamp": 1687183425745,
     "user": {
      "displayName": "Tahuruzzoha Tuhin",
      "userId": "08192377551345148302"
     },
     "user_tz": -360
    },
    "id": "9ac67da0",
    "outputId": "99d49c1b-0514-4681-dbfc-d3673b3af6b5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "#Extract the body and padding the sequence in an uniform length\n",
    "max_length = 15\n",
    "df_body = []\n",
    "for i in df[\"body\"]:\n",
    "    df_body.append(i[:max_length])\n",
    "\n",
    "\n",
    "for item in df_body:\n",
    "    if len(item) < max_length:\n",
    "        for i in range(max_length-len(item)):\n",
    "            item.append(0)\n",
    "\n",
    "#Split the train data and validation data as X_train-(80%) and x_val-(20%)\n",
    "X_train = list()\n",
    "X_val = list()\n",
    "len_df_body = len(df_body)\n",
    "X_percent_80 = ((len_df_body*80)//100)\n",
    "\n",
    "for i in range(len_df_body):\n",
    "    if i <= X_percent_80-1:\n",
    "        X_train.append(df_body[i])\n",
    "    if i >= X_percent_80:\n",
    "        X_val.append(df_body[i])\n",
    "\n",
    "\n",
    "#Extract the isTopLevel and convert the data in numeric type\n",
    "isTopLevel_trans = list()\n",
    "for item in isTopLevel:\n",
    "    if item == True or item == 'True':\n",
    "        isTopLevel_trans.append(1)\n",
    "    if item == False or item == 'False':\n",
    "        isTopLevel_trans.append(0)\n",
    "\n",
    "#Split the train data and validation data as y_train-(80%) and y_val-(20%)\n",
    "y_train = list()\n",
    "y_val = list()\n",
    "len_isTopLevel_trans = len(isTopLevel_trans)\n",
    "y_percent_80 = ((len_isTopLevel_trans*80)//100)\n",
    "\n",
    "\n",
    "for i in range(len_isTopLevel_trans):\n",
    "    if i <= y_percent_80-1:\n",
    "        y_train.append(isTopLevel_trans[i])\n",
    "    if i >= y_percent_80:\n",
    "        y_val.append(isTopLevel_trans[i])\n",
    "\n",
    "\n",
    "#Cast the data type as tensor float\n",
    "X_train = tf.cast(X_train, dtype=tf.float32)\n",
    "X_val = tf.cast(X_val, dtype=tf.float32)\n",
    "y_train = tf.cast(y_train, dtype=tf.float32)\n",
    "y_val = tf.cast(y_val, dtype=tf.float32)\n",
    "\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "62e2528a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 598,
     "status": "ok",
     "timestamp": 1687183516348,
     "user": {
      "displayName": "Tahuruzzoha Tuhin",
      "userId": "08192377551345148302"
     },
     "user_tz": -360
    },
    "id": "62e2528a",
    "outputId": "4fe067b2-0dc9-4c69-c8fa-ccff65f5dff6",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 15, 300)           156000    \n",
      "                                                                 \n",
      " conv1d (Conv1D)             (None, 14, 50)            30050     \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 12, 50)            7550      \n",
      "                                                                 \n",
      " conv1d_2 (Conv1D)           (None, 9, 50)             10050     \n",
      "                                                                 \n",
      " conv1d_3 (Conv1D)           (None, 5, 50)             12550     \n",
      "                                                                 \n",
      " global_max_pooling1d (Globa  (None, 50)               0         \n",
      " lMaxPooling1D)                                                  \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 50)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 100)               5100      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 101       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 221,401\n",
      "Trainable params: 221,401\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Generate embedding dimension\n",
    "embedding_dim = 300\n",
    "vocab_size = len(word_to_int) + 1\n",
    "\n",
    "# X_train = tf.convert_to_tensor(X_train)\n",
    "# X_val = tf.convert_to_tensor(X_val)\n",
    "# y_train = tf.convert_to_tensor(y_train)\n",
    "# y_val = tf.convert_to_tensor(y_val)\n",
    "\n",
    "\n",
    "# Create the model (CNN)\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=max_length,  trainable=True))\n",
    "model.add(Conv1D(filters=50, kernel_size=2, activation='relu'))\n",
    "model.add(Conv1D(filters=50, kernel_size=3, activation='relu'))\n",
    "model.add(Conv1D(filters=50, kernel_size=4, activation='relu'))\n",
    "model.add(Conv1D(filters=50, kernel_size=5, activation='relu'))\n",
    "model.add(GlobalMaxPooling1D())\n",
    "model.add(Flatten())\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Print the model summary\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7c382c1c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5436,
     "status": "ok",
     "timestamp": 1687183526831,
     "user": {
      "displayName": "Tahuruzzoha Tuhin",
      "userId": "08192377551345148302"
     },
     "user_tz": -360
    },
    "id": "7c382c1c",
    "outputId": "15eff96e-b78b-4330-fdaf-f5ae7071c676"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "2/2 [==============================] - 3s 463ms/step - loss: 0.6942 - accuracy: 0.4750 - val_loss: 0.6932 - val_accuracy: 0.6000\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 0s 103ms/step - loss: 0.6900 - accuracy: 0.6500 - val_loss: 0.6962 - val_accuracy: 0.4000\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 0.6866 - accuracy: 0.5250 - val_loss: 0.6974 - val_accuracy: 0.4000\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.6822 - accuracy: 0.5250 - val_loss: 0.6963 - val_accuracy: 0.4000\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 0.6762 - accuracy: 0.5875 - val_loss: 0.6962 - val_accuracy: 0.4000\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 0.6669 - accuracy: 0.6125 - val_loss: 0.7015 - val_accuracy: 0.4000\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.6581 - accuracy: 0.5250 - val_loss: 0.7060 - val_accuracy: 0.4000\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.6436 - accuracy: 0.5375 - val_loss: 0.7091 - val_accuracy: 0.4000\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.6233 - accuracy: 0.5625 - val_loss: 0.7203 - val_accuracy: 0.4000\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.5997 - accuracy: 0.5625 - val_loss: 0.7390 - val_accuracy: 0.4000\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.7390 - accuracy: 0.4000\n",
      "Validation Loss: 0.7390\n",
      "Validation Accuracy: 0.4000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Train the model\n",
    "batch_size = 64\n",
    "epochs = 10\n",
    "model.fit(x=X_train, y=y_train, batch_size=batch_size, epochs=epochs, validation_data=(X_val, y_val))\n",
    "\n",
    "# Evaluate the model on the validation set\n",
    "loss, accuracy = model.evaluate(np.array(X_val), np.array(y_val))\n",
    "print(f'Validation Loss: {loss:.4f}')\n",
    "print(f'Validation Accuracy: {accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a23207a5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 441
    },
    "executionInfo": {
     "elapsed": 572,
     "status": "ok",
     "timestamp": 1687183622753,
     "user": {
      "displayName": "Tahuruzzoha Tuhin",
      "userId": "08192377551345148302"
     },
     "user_tz": -360
    },
    "id": "a23207a5",
    "outputId": "db211401-28c2-4ad0-e67d-150c4597e182"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 6ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-064e9b88-6fd2-4dfd-bf43-7ecb201106c3\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predicted_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80 rows × 1 columns</p>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-064e9b88-6fd2-4dfd-bf43-7ecb201106c3')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-064e9b88-6fd2-4dfd-bf43-7ecb201106c3 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-064e9b88-6fd2-4dfd-bf43-7ecb201106c3');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "    predicted_label\n",
       "0               1.0\n",
       "1               1.0\n",
       "2               0.0\n",
       "3               0.0\n",
       "4               0.0\n",
       "..              ...\n",
       "75              0.0\n",
       "76              0.0\n",
       "77              0.0\n",
       "78              0.0\n",
       "79              0.0\n",
       "\n",
       "[80 rows x 1 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict the labels for the test set\n",
    "predicted_labels = model.predict(np.array(X_train))\n",
    "predicted_labels = np.round(predicted_labels).flatten()\n",
    "\n",
    "# Create a DataFrame with the predicted labels\n",
    "predicted_df = pd.DataFrame({'predicted_label': predicted_labels})\n",
    "# Export the DataFrame to Excel\n",
    "predicted_df.to_csv('predictions.csv', index=False)\n",
    "predicted_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ae1e6e04",
   "metadata": {
    "executionInfo": {
     "elapsed": 586,
     "status": "ok",
     "timestamp": 1687183637475,
     "user": {
      "displayName": "Tahuruzzoha Tuhin",
      "userId": "08192377551345148302"
     },
     "user_tz": -360
    },
    "id": "ae1e6e04"
   },
   "outputs": [],
   "source": [
    "from PIL import Image, ImageChops, ImageEnhance\n",
    "import os\n",
    "import itertools\n",
    "from keras.layers import Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.preprocessing import LabelEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc269518",
   "metadata": {
    "id": "bc269518"
   },
   "outputs": [],
   "source": [
    "# def convert_to_ela_image(path, quality):\n",
    "#     temp_filename = 'temp_file_name.jpg'\n",
    "#     ela_filename = 'temp_ela.png'\n",
    "\n",
    "#     image = Image.open(path).convert('RGB')\n",
    "#     image.save(temp_filename, 'JPEG', quality = quality)\n",
    "#     temp_image = Image.open(temp_filename)\n",
    "\n",
    "#     ela_image = ImageChops.difference(image, temp_image)\n",
    "\n",
    "#     extrema = ela_image.getextrema()\n",
    "#     max_diff = max([ex[1] for ex in extrema])\n",
    "#     if max_diff == 0:\n",
    "#         max_diff = 1\n",
    "#     scale = 255.0 / max_diff\n",
    "\n",
    "#     ela_image = ImageEnhance.Brightness(ela_image).enhance(scale)\n",
    "\n",
    "#     return ela_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3429650b",
   "metadata": {
    "id": "3429650b"
   },
   "outputs": [],
   "source": [
    "# image_size = (128, 128)\n",
    "# def prepare_image(image_path):\n",
    "#     return np.array(convert_to_ela_image(image_path, 90).resize(image_size)).flatten()/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c113e9",
   "metadata": {
    "id": "f2c113e9"
   },
   "outputs": [],
   "source": [
    "\n",
    "# path = './image_data'\n",
    "# X = []\n",
    "# for dirname, _, filenames in os.walk(path):\n",
    "#     for filename in filenames:\n",
    "#         if filename.endswith('jpg') or filename.endswith('png'):\n",
    "#             full_path = os.path.join(dirname, filename)\n",
    "#             X.append(prepare_image(full_path))\n",
    "\n",
    "# # print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "83062567",
   "metadata": {
    "executionInfo": {
     "elapsed": 1346,
     "status": "ok",
     "timestamp": 1687183642457,
     "user": {
      "displayName": "Tahuruzzoha Tuhin",
      "userId": "08192377551345148302"
     },
     "user_tz": -360
    },
    "id": "83062567"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# def image_pross(path):\n",
    "#     path = path\n",
    "#     #     print(path)\n",
    "#     # Load the images\n",
    "#     image_data = []\n",
    "#     image_width = 560\n",
    "#     image_height = 560\n",
    "#     for dirname, _, filenames in os.walk(path):\n",
    "#         for filename in filenames:\n",
    "#             if filename.endswith('jpg') or filename.endswith('png'):\n",
    "#                 full_path = os.path.join(dirname, filename)\n",
    "#                 image = cv2.imread(full_path)  # Load the image using OpenCV\n",
    "#                 image = cv2.resize(image, (image_width, image_height))  # Resize the image to match your model's input shape\n",
    "#                 image_data.append(image)\n",
    "\n",
    "\n",
    "#     # Convert the list of images to a NumPy array\n",
    "#     image_data = np.array(image_data)\n",
    "\n",
    "#     # Normalize the image data if necessary\n",
    "#     image_data = image_data / 255.0  # Normalize pixel values to the range [0, 1]\n",
    "\n",
    "#     # Predict using the model\n",
    "#     # predictions = model.predict(image_data)\n",
    "# #     print(image_data)\n",
    "#     return image_data\n",
    "#     # print(\"Done!\")\n",
    "\n",
    "# Function to preprocess image data\n",
    "def preprocess_image_data(path, image_width, image_height):\n",
    "    image_data = []\n",
    "    for dirname, _, filenames in os.walk(path):\n",
    "        for filename in filenames:\n",
    "            if filename.endswith('jpg') or filename.endswith('png'):\n",
    "                full_path = os.path.join(dirname, filename)\n",
    "                image = cv2.imread(full_path)\n",
    "                image = cv2.resize(image, (image_width, image_height))\n",
    "                image_data.append(image)\n",
    "\n",
    "    image_data = np.array(image_data)\n",
    "    image_data = image_data / 255.0  # Normalize pixel values to the range [0, 1]\n",
    "    return image_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a7d95343",
   "metadata": {
    "executionInfo": {
     "elapsed": 1900,
     "status": "ok",
     "timestamp": 1687183659767,
     "user": {
      "displayName": "Tahuruzzoha Tuhin",
      "userId": "08192377551345148302"
     },
     "user_tz": -360
    },
    "id": "a7d95343"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "\n",
    "# Define the paths\n",
    "source_dir = '/content/drive/MyDrive/Colab Notebooks/image_data'  # Directory containing all 100 images\n",
    "train_dir = './train'  # Directory for training images\n",
    "val_dir = './validation'  # Directory for validation images\n",
    "\n",
    "# Create the directories if they don't exist\n",
    "# os.makedirs(image_data, exist_ok=True)\n",
    "os.makedirs(train_dir, exist_ok=True)\n",
    "os.makedirs(val_dir, exist_ok=True)\n",
    "\n",
    "# Shuffle the image list\n",
    "image_list = os.listdir(source_dir)\n",
    "random.shuffle(image_list)\n",
    "\n",
    "# len(image_list)\n",
    "# Split the images into train and validation sets\n",
    "train_images = image_list[:80]  # Select the first 80 images for training\n",
    "val_images = image_list[80:]  # Select the remaining 20 images for validation\n",
    "\n",
    "# print(train_images)\n",
    "\n",
    "# for i in train_images:\n",
    "#     if \"fake\" in i:\n",
    "#         print(i)\n",
    "# Move the images to the corresponding directories\n",
    "i=1\n",
    "for image in train_images:\n",
    "    image_path = os.path.join(source_dir, image)\n",
    "    if 'fake' in image:\n",
    "        shutil.copy(image_path, os.path.join(train_dir, f'fake-{i}.jpg'))\n",
    "    else:\n",
    "        shutil.copy(image_path, os.path.join(train_dir, f'real-{i}.jpg'))\n",
    "    i += 1\n",
    "\n",
    "i=1\n",
    "for image in val_images:\n",
    "    image_path = os.path.join(source_dir, image)\n",
    "    if 'fake' in image:\n",
    "        shutil.copy(image_path, os.path.join(val_dir, f'fake-{i}.jpg'))\n",
    "    else:\n",
    "        shutil.copy(image_path, os.path.join(val_dir, f'real-{i}.jpg'))\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "hPlfQOs14_b0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 577,
     "status": "ok",
     "timestamp": 1687183665366,
     "user": {
      "displayName": "Tahuruzzoha Tuhin",
      "userId": "08192377551345148302"
     },
     "user_tz": -360
    },
    "id": "hPlfQOs14_b0",
    "outputId": "3b8f24d6-a479-46b2-defd-15989cf24f8c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(val_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a402aff9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2986,
     "status": "ok",
     "timestamp": 1687183684098,
     "user": {
      "displayName": "Tahuruzzoha Tuhin",
      "userId": "08192377551345148302"
     },
     "user_tz": -360
    },
    "id": "a402aff9",
    "outputId": "6323aaae-60bc-4a4d-82bc-5ae277f0b769"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Preprocess image data\n",
    "image_width = 560\n",
    "image_height = 560\n",
    "image_train = preprocess_image_data(train_dir, image_width, image_height)\n",
    "image_val = preprocess_image_data(val_dir, image_width, image_height)\n",
    "print(len(image_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b0a1eabc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 888,
     "status": "ok",
     "timestamp": 1687183688756,
     "user": {
      "displayName": "Tahuruzzoha Tuhin",
      "userId": "08192377551345148302"
     },
     "user_tz": -360
    },
    "id": "b0a1eabc",
    "outputId": "1b43f904-7446-4d8e-8f3a-bb9e17f60384"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " image_input (InputLayer)       [(None, 560, 560, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " text_input (InputLayer)        [(None, 15)]         0           []                               \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 556, 556, 6)  456         ['image_input[0][0]']            \n",
      "                                                                                                  \n",
      " embedding_1 (Embedding)        (None, 15, 300)      156000      ['text_input[0][0]']             \n",
      "                                                                                                  \n",
      " activation (Activation)        (None, 556, 556, 6)  0           ['conv2d[0][0]']                 \n",
      "                                                                                                  \n",
      " conv1d_4 (Conv1D)              (None, 14, 50)       30050       ['embedding_1[0][0]']            \n",
      "                                                                                                  \n",
      " conv1d_5 (Conv1D)              (None, 13, 50)       45050       ['embedding_1[0][0]']            \n",
      "                                                                                                  \n",
      " conv1d_6 (Conv1D)              (None, 12, 50)       60050       ['embedding_1[0][0]']            \n",
      "                                                                                                  \n",
      " conv1d_7 (Conv1D)              (None, 11, 50)       75050       ['embedding_1[0][0]']            \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2D)   (None, 278, 278, 6)  0           ['activation[0][0]']             \n",
      "                                                                                                  \n",
      " global_max_pooling1d_1 (Global  (None, 50)          0           ['conv1d_4[0][0]']               \n",
      " MaxPooling1D)                                                                                    \n",
      "                                                                                                  \n",
      " global_max_pooling1d_2 (Global  (None, 50)          0           ['conv1d_5[0][0]']               \n",
      " MaxPooling1D)                                                                                    \n",
      "                                                                                                  \n",
      " global_max_pooling1d_3 (Global  (None, 50)          0           ['conv1d_6[0][0]']               \n",
      " MaxPooling1D)                                                                                    \n",
      "                                                                                                  \n",
      " global_max_pooling1d_4 (Global  (None, 50)          0           ['conv1d_7[0][0]']               \n",
      " MaxPooling1D)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 274, 274, 3)  453         ['max_pooling2d[0][0]']          \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 200)          0           ['global_max_pooling1d_1[0][0]', \n",
      "                                                                  'global_max_pooling1d_2[0][0]', \n",
      "                                                                  'global_max_pooling1d_3[0][0]', \n",
      "                                                                  'global_max_pooling1d_4[0][0]'] \n",
      "                                                                                                  \n",
      " activation_1 (Activation)      (None, 274, 274, 3)  0           ['conv2d_1[0][0]']               \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 100)          20100       ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " max_pooling2d_1 (MaxPooling2D)  (None, 137, 137, 3)  0          ['activation_1[0][0]']           \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 1)            101         ['dense_2[0][0]']                \n",
      "                                                                                                  \n",
      " flatten_1 (Flatten)            (None, 56307)        0           ['max_pooling2d_1[0][0]']        \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 56308)        0           ['dense_3[0][0]',                \n",
      "                                                                  'flatten_1[0][0]']              \n",
      "                                                                                                  \n",
      " dense_4 (Dense)                (None, 100)          5630900     ['concatenate_1[0][0]']          \n",
      "                                                                                                  \n",
      " dense_5 (Dense)                (None, 1)            101         ['dense_4[0][0]']                \n",
      "                                                                                                  \n",
      " activation_2 (Activation)      (None, 1)            0           ['dense_5[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 6,018,311\n",
      "Trainable params: 6,018,311\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "---------------------------\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name=None), name='dense_3/Sigmoid:0', description=\"created by layer 'dense_3'\")\n"
     ]
    }
   ],
   "source": [
    "# Define the text input\n",
    "text_input = Input(shape=(15,), name='text_input')\n",
    "\n",
    "# Generate embedding dimension\n",
    "embedding_dim = 300\n",
    "vocab_size = len(word_to_int) + 1\n",
    "\n",
    "# X_train = tf.convert_to_tensor(X_train)\n",
    "# X_val = tf.convert_to_tensor(X_val)\n",
    "# y_train = tf.convert_to_tensor(y_train)\n",
    "# y_val = tf.convert_to_tensor(y_val)\n",
    "\n",
    "\n",
    "# Create the model (CNN)\n",
    "# model = Sequential()\n",
    "# model.add()\n",
    "# Text CNN model\n",
    "text_embedding = Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=max_length,  trainable=True)(text_input)\n",
    "text_conv1 = Conv1D(filters=50, kernel_size=2, activation='relu')(text_embedding)\n",
    "text_conv2 = Conv1D(filters=50, kernel_size=3, activation='relu')(text_embedding)\n",
    "text_conv3 = Conv1D(filters=50, kernel_size=4, activation='relu')(text_embedding)\n",
    "text_conv4 = Conv1D(filters=50, kernel_size=5, activation='relu')(text_embedding)\n",
    "text_pool1 = GlobalMaxPooling1D()(text_conv1)\n",
    "text_pool2 = GlobalMaxPooling1D()(text_conv2)\n",
    "text_pool3 = GlobalMaxPooling1D()(text_conv3)\n",
    "text_pool4 = GlobalMaxPooling1D()(text_conv4)\n",
    "text_concat = Concatenate()([text_pool1, text_pool2, text_pool3, text_pool4])\n",
    "text_output = Dense(100, activation='relu')(text_concat)\n",
    "text_output = Dense(1, activation='sigmoid')(text_output)\n",
    "\n",
    "\n",
    "\n",
    "# Define the image input\n",
    "image_input = Input(shape=(image_width, image_height, 3), name='image_input')\n",
    "\n",
    "# Image CNN model\n",
    "image_conv1 = Conv2D(filters=6, kernel_size=(5, 5), strides=1, padding='valid')(image_input)\n",
    "image_activation1 = Activation('relu')(image_conv1)\n",
    "image_maxpool1 = MaxPooling2D(pool_size=(2, 2), strides=2)(image_activation1)\n",
    "image_conv2 = Conv2D(filters=3, kernel_size=(5, 5), strides=1, padding='valid')(image_maxpool1)\n",
    "image_activation2 = Activation('relu')(image_conv2)\n",
    "image_maxpool2 = MaxPooling2D(pool_size=(2, 2), strides=2)(image_activation2)\n",
    "image_flatten = Flatten()(image_maxpool2)\n",
    "\n",
    "# Concatenate the outputs from text and image models\n",
    "concatenated = Concatenate()([text_output, image_flatten])\n",
    "\n",
    "# Dense layers and final output\n",
    "dense1 = Dense(100, activation='relu')(concatenated)\n",
    "dense2 = Dense(1, activation='sigmoid')(dense1)\n",
    "output = Activation('sigmoid')(dense2)\n",
    "\n",
    "final_model = Model(inputs=[text_input, image_input], outputs=output)\n",
    "# Compile the model\n",
    "# final_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "final_model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "# Print the model summary\n",
    "final_model.summary()\n",
    "print(\"---------------------------\")\n",
    "print(text_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "50aea663",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 277456,
     "status": "ok",
     "timestamp": 1687184700481,
     "user": {
      "displayName": "Tahuruzzoha Tuhin",
      "userId": "08192377551345148302"
     },
     "user_tz": -360
    },
    "id": "50aea663",
    "outputId": "cac85223-512f-4101-81ae-eabbb7639924"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "2/2 [==============================] - 29s 10s/step - loss: 0.5130 - accuracy: 0.7000 - val_loss: 0.7024 - val_accuracy: 0.6500\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 27s 8s/step - loss: 0.5129 - accuracy: 0.7000 - val_loss: 0.6913 - val_accuracy: 0.6500\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 28s 10s/step - loss: 0.5128 - accuracy: 0.6375 - val_loss: 0.6783 - val_accuracy: 0.6500\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 27s 8s/step - loss: 0.5128 - accuracy: 0.6250 - val_loss: 0.6646 - val_accuracy: 0.6500\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 28s 10s/step - loss: 0.5128 - accuracy: 0.6000 - val_loss: 0.6467 - val_accuracy: 0.6500\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 28s 10s/step - loss: 0.5128 - accuracy: 0.5625 - val_loss: 0.6461 - val_accuracy: 0.6500\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 26s 8s/step - loss: 0.5128 - accuracy: 0.5750 - val_loss: 0.6573 - val_accuracy: 0.6500\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 28s 9s/step - loss: 0.5128 - accuracy: 0.6125 - val_loss: 0.6632 - val_accuracy: 0.6500\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 28s 10s/step - loss: 0.5128 - accuracy: 0.6125 - val_loss: 0.6668 - val_accuracy: 0.6500\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 26s 8s/step - loss: 0.5128 - accuracy: 0.6125 - val_loss: 0.6696 - val_accuracy: 0.6500\n"
     ]
    }
   ],
   "source": [
    "# %%capture captured_output\n",
    "# Train the multimodal model\n",
    "image_train = tf.cast(image_train, dtype=tf.float32)\n",
    "image_val = tf.cast(image_val, dtype=tf.float32)\n",
    "# Preprocess target labels\n",
    "label_encoder = LabelEncoder()\n",
    "y_train = label_encoder.fit_transform(y_train)  # Encode the labels\n",
    "y_val = label_encoder.transform(y_val)  # Encode the labels\n",
    "\n",
    "# y_train = tf.cast(y_train, dtype=tf.float32)\n",
    "# y_val = tf.cast(y_val, dtype=tf.float32)\n",
    "\n",
    "# Train the multimodal model\n",
    "history = final_model.fit(\n",
    "    x=[X_train, image_train],  # Pass both text and image inputs\n",
    "    y=y_train,  # Target labels\n",
    "    validation_data=([X_val, image_val], y_val),  # Validation data\n",
    "    epochs=10,\n",
    "    batch_size=64\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f77813",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 432,
     "status": "ok",
     "timestamp": 1687165520856,
     "user": {
      "displayName": "Tahuruzzoha Tuhin",
      "userId": "08192377551345148302"
     },
     "user_tz": -360
    },
    "id": "25f77813",
    "outputId": "11e3f6b6-3aa6-4ca6-afa4-b4b73c54f249"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b777ff3a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1687165522957,
     "user": {
      "displayName": "Tahuruzzoha Tuhin",
      "userId": "08192377551345148302"
     },
     "user_tz": -360
    },
    "id": "b777ff3a",
    "outputId": "1d029e61-4231-463c-9619-714a521207c2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(image_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "foxpU38K4hMz",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1687165525147,
     "user": {
      "displayName": "Tahuruzzoha Tuhin",
      "userId": "08192377551345148302"
     },
     "user_tz": -360
    },
    "id": "foxpU38K4hMz",
    "outputId": "b28b0ae1-3cea-43c3-f337-167541049a6b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "KMjFfZxY4jq4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 668,
     "status": "ok",
     "timestamp": 1687165528313,
     "user": {
      "displayName": "Tahuruzzoha Tuhin",
      "userId": "08192377551345148302"
     },
     "user_tz": -360
    },
    "id": "KMjFfZxY4jq4",
    "outputId": "efae5a08-c3f9-401d-8732-97e366b0718e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(image_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "603b7b14",
   "metadata": {
    "id": "603b7b14",
    "outputId": "6a466c6b-b6e4-43f2-b6fe-33fa7c97b8fd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([80, 128, 128, 3])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_train = tf.cast(image_train, dtype=tf.float32)\n",
    "image_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca1c1ca",
   "metadata": {
    "id": "5ca1c1ca",
    "outputId": "c8e04a62-bd68-4100-b838-e533ef267760"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-19 11:10:07.359043: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 22523200 exceeds 10% of free system memory.\n",
      "2023-06-19 11:10:07.386887: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 22523200 exceeds 10% of free system memory.\n",
      "2023-06-19 11:10:07.396564: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 22523200 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Graph disconnected: cannot obtain value for tensor KerasTensor(type_spec=TensorSpec(shape=(None, 560, 560, 3), dtype=tf.float32, name='conv2d_input'), name='conv2d_input', description=\"created by layer 'conv2d_input'\") at layer \"conv2d\". The following previous layers were accessed without issue: ['embedding', 'conv1d']",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 21\u001b[0m\n\u001b[1;32m     19\u001b[0m dense1 \u001b[38;5;241m=\u001b[39m Dense(\u001b[38;5;241m100\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m)(concatenated)\n\u001b[1;32m     20\u001b[0m output \u001b[38;5;241m=\u001b[39m Dense(\u001b[38;5;241m1\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msigmoid\u001b[39m\u001b[38;5;124m'\u001b[39m)(dense1)\n\u001b[0;32m---> 21\u001b[0m final_model \u001b[38;5;241m=\u001b[39m Model(inputs\u001b[38;5;241m=\u001b[39m[model\u001b[38;5;241m.\u001b[39minput, image_input], outputs\u001b[38;5;241m=\u001b[39moutput)\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# Compile the model\u001b[39;00m\n\u001b[1;32m     23\u001b[0m final_model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m, loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/trackable/base.py:205\u001b[0m, in \u001b[0;36mno_automatic_dependency_tracking.<locals>._method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_self_setattr_tracking \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    204\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 205\u001b[0m   result \u001b[38;5;241m=\u001b[39m method(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    207\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_self_setattr_tracking \u001b[38;5;241m=\u001b[39m previous_value  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/keras/engine/functional.py:167\u001b[0m, in \u001b[0;36mFunctional.__init__\u001b[0;34m(self, inputs, outputs, name, trainable, **kwargs)\u001b[0m\n\u001b[1;32m    158\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\n\u001b[1;32m    159\u001b[0m         [\n\u001b[1;32m    160\u001b[0m             functional_utils\u001b[38;5;241m.\u001b[39mis_input_keras_tensor(t)\n\u001b[1;32m    161\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mnest\u001b[38;5;241m.\u001b[39mflatten(inputs)\n\u001b[1;32m    162\u001b[0m         ]\n\u001b[1;32m    163\u001b[0m     ):\n\u001b[1;32m    164\u001b[0m         inputs, outputs \u001b[38;5;241m=\u001b[39m functional_utils\u001b[38;5;241m.\u001b[39mclone_graph_nodes(\n\u001b[1;32m    165\u001b[0m             inputs, outputs\n\u001b[1;32m    166\u001b[0m         )\n\u001b[0;32m--> 167\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_graph_network(inputs, outputs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/trackable/base.py:205\u001b[0m, in \u001b[0;36mno_automatic_dependency_tracking.<locals>._method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_self_setattr_tracking \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    204\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 205\u001b[0m   result \u001b[38;5;241m=\u001b[39m method(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    207\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_self_setattr_tracking \u001b[38;5;241m=\u001b[39m previous_value  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/keras/engine/functional.py:266\u001b[0m, in \u001b[0;36mFunctional._init_graph_network\u001b[0;34m(self, inputs, outputs)\u001b[0m\n\u001b[1;32m    263\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_input_coordinates\u001b[38;5;241m.\u001b[39mappend((layer, node_index, tensor_index))\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# Keep track of the network's nodes and layers.\u001b[39;00m\n\u001b[0;32m--> 266\u001b[0m nodes, nodes_by_depth, layers, _ \u001b[38;5;241m=\u001b[39m _map_graph_network(\n\u001b[1;32m    267\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minputs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutputs\n\u001b[1;32m    268\u001b[0m )\n\u001b[1;32m    269\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_network_nodes \u001b[38;5;241m=\u001b[39m nodes\n\u001b[1;32m    270\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_nodes_by_depth \u001b[38;5;241m=\u001b[39m nodes_by_depth\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/keras/engine/functional.py:1142\u001b[0m, in \u001b[0;36m_map_graph_network\u001b[0;34m(inputs, outputs)\u001b[0m\n\u001b[1;32m   1140\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mnest\u001b[38;5;241m.\u001b[39mflatten(node\u001b[38;5;241m.\u001b[39mkeras_inputs):\n\u001b[1;32m   1141\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mid\u001b[39m(x) \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m computable_tensors:\n\u001b[0;32m-> 1142\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1143\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGraph disconnected: cannot obtain value for \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1144\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtensor \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m at layer \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlayer\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   1145\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe following previous layers were accessed \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1146\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwithout issue: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlayers_with_complete_input\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1147\u001b[0m         )\n\u001b[1;32m   1148\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mnest\u001b[38;5;241m.\u001b[39mflatten(node\u001b[38;5;241m.\u001b[39moutputs):\n\u001b[1;32m   1149\u001b[0m     computable_tensors\u001b[38;5;241m.\u001b[39madd(\u001b[38;5;28mid\u001b[39m(x))\n",
      "\u001b[0;31mValueError\u001b[0m: Graph disconnected: cannot obtain value for tensor KerasTensor(type_spec=TensorSpec(shape=(None, 560, 560, 3), dtype=tf.float32, name='conv2d_input'), name='conv2d_input', description=\"created by layer 'conv2d_input'\") at layer \"conv2d\". The following previous layers were accessed without issue: ['embedding', 'conv1d']"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input\n",
    "\n",
    "\n",
    "# Define the image input\n",
    "image_input = Input(shape=(15, 15, 3), name='image_data')\n",
    "\n",
    "\n",
    "image_model = Sequential()\n",
    "image_model.add(Conv2D(filters=6, kernel_size=(5, 5), strides=1, padding='valid', input_shape=(560, 560, 3)))\n",
    "image_model.add(Activation('relu'))\n",
    "image_model.add(MaxPooling2D(pool_size=(2, 2), strides=2))\n",
    "image_model.add(Conv2D(filters=3, kernel_size=(5, 5), strides=1, padding='valid'))\n",
    "image_model.add(Activation('relu'))\n",
    "image_model.add(MaxPooling2D(pool_size=(2, 2), strides=2))\n",
    "image_model.add(Flatten())\n",
    "\n",
    "\n",
    "concatenated = tf.keras.layers.Concatenate()([model.output, image_model.output])\n",
    "dense1 = Dense(100, activation='relu')(concatenated)\n",
    "output = Dense(1, activation='sigmoid')(dense1)\n",
    "final_model = Model(inputs=[model.input, image_input], outputs=output)\n",
    "# Compile the model\n",
    "final_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Print the model summary\n",
    "final_model.summary()\n",
    "\n",
    "# Train the multimodal model\n",
    "history = final_model.fit(\n",
    "    [text_train, image_train],  # Pass both text and image inputs\n",
    "    y_train,  # Target labels\n",
    "    validation_data=([text_val, image_val], y_val),  # Validation data\n",
    "    epochs=15,\n",
    "    batch_size=16\n",
    ")\n",
    "\n",
    "# # Evaluate the model\n",
    "# loss, accuracy = model.evaluate([text_test, image_test], y_test)\n",
    "# print(\"Test Loss:\", loss)\n",
    "# print(\"Test Accuracy:\", accuracy)\n",
    "\n",
    "# # Export the predicted values\n",
    "# y_pred = model.predict([text_test, image_test])\n",
    "# y_pred = [1 if pred > 0.5 else 0 for pred in y_pred]\n",
    "\n",
    "# import pandas as pd\n",
    "\n",
    "# # Create a DataFrame with the predicted values\n",
    "# df_pred =\n",
    "# df_pred = pd.DataFrame({'predicted_class': y_pred})\n",
    "\n",
    "# # Export the DataFrame to a CSV file\n",
    "# df_pred.to_csv('predicted_values.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
